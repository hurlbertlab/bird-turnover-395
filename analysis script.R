## ENEC 395: Climate and avian turnover script 3
# Final products: histogram pdf, bbcSpeciesCount: table of bbc aou counts 
# filtered by relevant sites and breeders, counts_list: list of tables of bbs data 
# for each bbc site, removed transient

library(dplyr)
library(sf)
library(ggplot2)
# Checking temporal distribution of surveys
# must run filtering scripts first and save objects for counts_list

bbcSites.3 = read.csv("bbcSitesFin2.csv")
bbsCounts.3 = read.csv("subset_bbsCounts.csv")
bbsRoutes.3 = read.csv("subset_bbsRoutes.csv")

bbc_counts = read.csv("bbc-data/bbc_counts.csv", stringsAsFactors = FALSE) 
for(n in 1: length(bbc_counts$count)) {
  if(bbc_counts$count[n] == "+") {bbc_counts$count[n] = .25}
  if(bbc_counts$count[n] == "LU") {bbc_counts$count[n] = 1.0}
}
#, na.strings = c("+", "LU"), stringsAsFactors = FALSE)


pdf(file = "bbs_hist.pdf")
for(i in 1:length(counts_list)) {
  hist(counts_list[[i]]$year, breaks = 20, xlab = "year", 
       main = paste("Site ", i))
}
dev.off()
#####



#####
pdf(file = "bbs_hist_byroute.pdf")
for(i in 1:length(counts_list)) {
  
  par(mfrow = c(1,2))
  
  occurrence1 = bbsWeather %>% 
    filter(stateroute %in% counts_list[[i]]$stateroute, year >= bbcSitesFin$y1[i] - 2 & year <= bbcSitesFin$y1[i] +2)  
  
  occurrence2 = bbsWeather %>% 
    filter(stateroute %in% counts_list[[i]]$stateroute, year >= bbcSitesFin$y2[i] - 2 & year <= bbcSitesFin$y2[i] +2) 
  
  barplot(table(occurrence1$stateroute), xlab = "Y1 state route surveys", main = paste("Site ", i, ":", bbcSitesFin$State[i]))
  barplot(table(occurrence2$stateroute), xlab = "Y2 state route surveys")
  
}
dev.off()
par(mfrow = c(1, 1))

pdf(file = "map routes and surveys.pdf")
us_states2163 = st_transform(us_states, 2163)
us_map = tm_shape(us_states2163) + 
  tm_polygons() + 
  tm_layout(frame = FALSE) 

us_map = us_map + 
  tm_shape(sf_bbcSites)+
  tm_dots(col = "red", size = .07, shape = 8)
  
for( n in 1: length(dist_list)) {
  us_map = us_map + 
    tm_shape(dist_list[[n]]) +
    tm_dots()
}

print(us_map)

dev.off()

# assign bbs landcover

landcover_US = read.csv("fragmentation_indices_nlcd_simplified.csv")
newcode <- data.frame(class = seq(1,9), 
                                   legend = c("Open water", "Urban", "Barren", "Forest", "Shrubland", 
                                              "Agricultural", "Grasslands", "Wetlands", "Perennial ice, snow"))
landcover_US_2001 = landcover_US %>%
  select(file:prop.landscape) %>%
  filter(year == "2001") %>%
  filter(stateroute %in% bbsRoutes.3$stateroute)

landcover_US_2001.legend = left_join(landcover_US_2001, newcode, by = "class")

landcover_Can = read.csv("fragmentation_indices_canada.csv")
legend_can = read.csv("canada-landcover-legend.txt")

landcover_Can_2001 = landcover_Can %>% 
  select(file:prop.landscape) %>%
  filter(year == "2000") %>%
  filter(stateroute %in% bbsRoutes.3$stateroute) 

landcover_Can_2001.legend = left_join(landcover_Can_2001, legend_can, by = "class") %>%
  rename(legend = label) %>%
  select(-definition)

# combine US and Canada landcover, choose BBS roots to match 

landcover = bind_rows(landcover_Can_2001.legend, landcover_US_2001.legend)

bbsroute.landcover = landcover %>% group_by(stateroute) %>% filter(prop.landscape == max(prop.landscape))

bbcSites.3 = rename(bbcSites.3, bbc_site = X)

bbsroute.landcover = left_join(bbsroute.landcover, bbsRoutes.3, by = "stateroute")# %>% select(-X) 
  
bbsroute.landcover_fin = left_join(bbsroute.landcover, bbcSites.3, by = "bbc_site") %>%
  select(c(year:class, prop.landscape:sitename, state:elev_m)) %>% group_by(bbc_site)

pair = data.frame(bbc_site = 1:17, bbc_siteID = bbcSites.3$siteID, y1 = bbcSites.3$y1, y2 = bbcSites.3$y2,
                  stateroute = c("47019", "18009", "72028", "14016", "14016",
                                 "18009", "46030", "18009", "80002", "18009",
                                 "61064", "14047", "61121", "68001", "80002", "68220", "14016"))

# compare abundance of individuals 

bbcSpeciesCount = bbc_counts %>%
  filter(siteID %in% bbcSites.3$siteID) %>%
  filter(status == "breeder") 

bbcSpeciesCount$count[is.na(bbcSpeciesCount$count)] = 0
bbcSpeciesCount$count = as.numeric(bbcSpeciesCount$count)
bbcSpeciesCount$count = ceiling(bbcSpeciesCount$count)

pair.counts = data.frame(bbc = integer(), species1.y1 = integer(), individ1.y1 = integer(), species1.y2 = integer(), individ1.y2 = integer(),
                         bbs = integer(), bbs.y1 = integer(), species2.y1 = integer(), individ2.y1 = numeric(),
                         bbs.y2 = integer(), species2.y2 = integer(), individ2.y2 = integer())
for (n in 1:nrow(pair)) {
  bbc = pair$bbc_siteID[n]
  bbs = pair$stateroute[n]
  y1 = pair$y1[n]
  y2 = pair$y2[n]
  
  
  df1.y1 = filter(bbcSpeciesCount, bbcSpeciesCount$siteID == bbc,
               bbcSpeciesCount$year == y1) 
  df1.y2 = filter(bbcSpeciesCount, bbcSpeciesCount$siteID == bbc,
                  bbcSpeciesCount$year == y2)
  
  df2 = bbsCounts.3 %>% filter(bbsCounts.3$stateroute == bbs)
  
  df2.y1 = filter(df2, df2$year == y1 - min(abs(unique(df2$year) - y1)))
  bbs.y1 =  y1 - min(abs(unique(df2$year) - y1))
  if(sum(df2.y1$speciestotal) == 0) {
    df2.y1 = filter(df2, df2$year == y1 + min(abs(unique(df2$year) - y1)))
    bbs.y1 = y1 + min(abs(unique(df2$year) - y1))
  }
  df2.y2 = filter(df2, df2$year == y2 - min(abs(unique(df2$year) - y2)))
  bbs.y2 = y2 - min(abs(unique(df2$year) - y2))
  if(sum(df2.y2$speciestotal) == 0) {
    df2.y2 = filter(df2, df2$year ==  y2 + min(abs(unique(df2$year) - y2)))
    bbs.y2 = y2 + min(abs(unique(df2$year) - y2))
  }
  
  species1.y1 = nrow(df1.y1)
  individ1.y1 = sum(df1.y1$count)
  species1.y2 = nrow(df1.y2)
  individ1.y2 = sum(df1.y2$count)
  
  species2.y1 = nrow(df2.y1)
  individ2.y1 = sum(df2.y1$speciestotal)
  species2.y2 = nrow(df2.y2)
  individ2.y2 = sum(df2.y2$speciestotal)
  
  df = data.frame(bbc, species1.y1, individ1.y1, species1.y2, individ1.y2,
                  bbs, bbs.y1, species2.y1, individ2.y1, bbs.y2, species2.y2, individ2.y2)
  pair.counts = rbind(pair.counts, df)
}

# for loop calculating # of species for subsets of bbs with same number of individuals as bbc
#subsets

# Jaccard similarity coefficient
# J = # species shared / total # unique species
output = data_frame(bbc = integer(), stateroute = integer(), mean.J = double())

for (s in 1:nrow(pair.counts)) {
  bbs.y1.all = bbsCounts.3 %>% filter(year == pair.counts$bbs.y1[s], stateroute == pair.counts$bbs[s])
  bbs.y2.all = bbsCounts.3 %>% filter(year == pair.counts$bbs.y2[s], stateroute == pair.counts$bbs[s])
  
  J.vals = vector()
  for (i in 1:100) {
    y1.subset = sample_n(bbs.y1.all, size = pair.counts$individ1.y1[s], replace = TRUE, weight = bbs.y1.all$speciestotal)
    y2.subset = sample_n(bbs.y2.all, size = pair.counts$individ1.y2[s], replace = TRUE, weight = bbs.y2.all$speciestotal)
    
    tmp.y1.species = y1.subset$aou
    tmp.y2.species = y2.subset$aou
    
    sharedspp = sum(tmp.y1.species %in% tmp.y2.species)
    if (length(tmp.y1.species) > length(tmp.y2.species)) {
      sharedspp = sum(tmp.y2.species %in% tmp.y1.species)}
    totalspp = length(tmp.y1.species) + length(tmp.y2.species) - sharedspp
    
    J.vals[i] = sharedspp/totalspp
  }
  tmpOut = data.frame(bbc = pair.counts$bbc[s], stateroute = pair.counts$bbs[s], J = mean(J.vals))
  output = rbind(output, tmpOut)
}

bbc.J = vector()
for (l in 1: nrow(pair.counts)) {
  tmp.y1.species = filter(bbcSpeciesCount, siteID == pair.counts$bbc[l], year == bbcSites.3$y1[l])$species
  tmp.y2.species = filter(bbcSpeciesCount, siteID == pair.counts$bbc[l], year == bbcSites.3$y2[l])$species
  
  sharedspp = sum(tmp.y1.species %in% tmp.y2.species)
  if (length(tmp.y1.species) > length(tmp.y2.species)) {
    sharedspp = sum(tmp.y2.species %in% tmp.y1.species)}
  totalspp = length(tmp.y1.species) + length(tmp.y2.species) - sharedspp
  
  bbc.J[l] = sharedspp/totalspp
}
output$bbc.J = bbc.J 

